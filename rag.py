#æ”¹ç”¨apiç‰ˆ
import os

os.environ["TOKENIZERS_PARALLELISM"] = "false"  # ç¦ç”¨ Hugging Face çš„å¹¶è¡Œè­¦å‘Š
os.environ["BITSANDBYTES_NOWELCOME"] = "1"  # ç¦æ­¢ bitsandbytes æ¬¢è¿ä¿¡æ¯
os.environ["WANDB_DISABLED"] = "true"  # ç¦ç”¨ wandb æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰

import faiss
import numpy as np
import pickle
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from sentence_transformers import SentenceTransformer
import pandas as pd
from config import config
import logging
from docx import Document  # ä»¥é˜²åé¢éœ€è¦ docx è§£æ

from openai import OpenAI
# åˆå§‹åŒ– API å®¢æˆ·ç«¯
client = OpenAI(api_key=config.API_KEY, base_url=config.BASE_URL)

##############################################################################
# 1. åŠ è½½æ¨¡å‹ä¸ç´¢å¼•
##############################################################################

# ä½¿ç”¨ API è·å–åµŒå…¥å‘é‡ï¼Œè°ƒç”¨ config ä¸­çš„ get_embedding æ–¹æ³•
def get_embedding_from_api(text):
    return np.array(config.get_embedding(text))  # è°ƒç”¨ config ä¸­çš„æ–¹æ³•æ¥è·å–åµŒå…¥å‘é‡


# åŠ è½½ FAISS ç´¢å¼•
index = faiss.read_index(str(config.FAISS_CACHE / "docs.index"))
print(f"âœ… FAISS ç´¢å¼•ç»´åº¦ï¼š{index.d}")

# åŠ è½½æ–‡ä»¶ååˆ—è¡¨
with open(str(config.FAISS_CACHE / "filenames.pkl"), "rb") as f:
    filenames = pickle.load(f)

# è·å– LLM å“åº”çš„åŠŸèƒ½ï¼Œç°åœ¨é€šè¿‡è°ƒç”¨ API æ¥è·å–å¤§æ¨¡å‹çš„å›ç­”
def get_llm_response_from_api(prompt):
    return config.get_llm_response(prompt)  # ä½¿ç”¨ config ä¸­çš„æ–¹æ³•æ¥è·å– LLM å“åº”

# ä½¿ç”¨ API è·å–åµŒå…¥å’Œæ¨¡å‹å“åº”
sample_text = "è¿™æ˜¯ä¸€æ®µç”¨äºæµ‹è¯•çš„æ–‡æœ¬"
embedding = get_embedding_from_api(sample_text)
print(f"âœ… è·å–çš„åµŒå…¥å‘é‡ï¼š{embedding[:5]}...")  # è¾“å‡ºå‰ 5 ä¸ªå…ƒç´ ä½œä¸ºç¤ºä¾‹

# é€šè¿‡ API è·å– LLM æ¨¡å‹çš„å“åº”
prompt = "è¯·ç”Ÿæˆä¸€æ®µå…³äºäººå·¥æ™ºèƒ½çš„ä»‹ç»ã€‚"
llm_response = get_llm_response_from_api(prompt)
print(f"âœ… LLM æ¨¡å‹çš„å“åº”ï¼š{llm_response}")


##############################################################################
# 2. æ–‡æ¡£åŠ è½½å‡½æ•°
##############################################################################

def load_document_content(filename):
    """
    æ ¹æ®æ–‡ä»¶ååŠ è½½æ–‡æœ¬å†…å®¹ã€‚identity.md ä½œä¸º AI è§’è‰²è®¾å®šã€‚
    """
    # ä½¿ç”¨é…ç½®ä¸­çš„çŸ¥è¯†åº“ç›®å½•
    file_path = os.path.join(config.REFERENCE_FOLDER, filename)

    # ç‰¹æ®Šå¤„ç† identity.md
    if filename == "identity.md":
        with open(file_path, "r", encoding="utf-8") as file:
            return f"[ç³»ç»Ÿè§’è‰²æç¤º]\n{file.read()}\n\n"

    if filename.endswith(".txt") or filename.endswith(".md"):
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()
    elif filename.endswith(".pdf"):
        from pypdf import PdfReader
        reader = PdfReader(file_path)
        return "\n".join([page.extract_text() for page in reader.pages if page.extract_text()])
    elif filename.endswith(".docx"):
        # åˆ©ç”¨ python-docx è¯»å–
        doc = Document(file_path)
        return "\n".join([para.text for para in doc.paragraphs])
    elif filename.endswith(".xlsx") or filename.endswith(".csv"):
        try:
            df = pd.read_excel(file_path) if filename.endswith(".xlsx") else pd.read_csv(file_path)
            return df.to_string(index=False)
        except Exception as e:
            return f"âŒ è¯»å– {filename} æ—¶å‡ºé”™: {str(e)}"
    elif filename.endswith(".pptx"):
        try:
            from pptx import Presentation
            prs = Presentation(file_path)
            text = []
            for slide in prs.slides:
                for shape in slide.shapes:
                    if shape.has_text_frame:
                        for paragraph in shape.text_frame.paragraphs:
                            text.append(paragraph.text)
            return "\n".join(text)
        except Exception as e:
            return f"âŒ è¯»å– {filename} æ—¶å‡ºé”™: {str(e)}"

    return "âŒ æ— æ³•è¯»å–è¯¥æ–‡æ¡£æ ¼å¼ï¼š" + filename


##############################################################################
# 3. æ£€ç´¢å‡½æ•°
##############################################################################

def retrieve_top_k_documents(query, k=3):
    """
    æ ¹æ®æŸ¥è¯¢è¯­å¥åœ¨ç´¢å¼•ä¸­æ‰¾åˆ°æœ€ç›¸å…³çš„ k ä¸ªæ–‡æ¡£ï¼Œå¹¶è¿”å›å…¶å†…å®¹ï¼ˆæˆªå–ï¼‰ã€‚
    """
    query_embedding = get_embedding_from_api(query)  # è·å–åµŒå…¥å‘é‡

    # ç¡®ä¿æŸ¥è¯¢å‘é‡æ˜¯äºŒç»´æ•°ç»„ (1, d)
    query_embedding = np.expand_dims(query_embedding, axis=0)

    print(f"âœ… æŸ¥è¯¢å‘é‡ç»´åº¦ï¼š{query_embedding.shape[0]}")

    _, idxs = index.search(query_embedding, k)

    retrieved_docs = []
    for i in idxs[0]:
        filename = filenames[i]
        content = load_document_content(filename)
        # è¿™é‡Œå¯ä»¥åªæˆªå–å‰1000å­—ç¬¦ï¼Œé¿å… Prompt è¿‡é•¿
        retrieved_docs.append(f"ğŸ“„ã€{filename}ã€‘\n{content[:100]}...")
    return retrieved_docs


##############################################################################
# 4. åˆ†å— (Chunk) + æ‘˜è¦ / æ”¹å†™
##############################################################################

def chunk_text(text, chunk_size=1000, overlap=200):
    """
    å°†é•¿æ–‡æœ¬åˆ†å—ï¼Œæ¯å— chunk_size ä¸ªå­—ç¬¦ï¼Œå¹¶åœ¨å—ä¹‹é—´ä¿ç•™ overlap ä¸ªå­—ç¬¦é‡å ï¼Œé¿å…å…³é”®ä¿¡æ¯è¢«åˆ‡æ–­ã€‚
    """
    chunks = []
    start = 0
    text_len = len(text)
    while start < text_len:
        end = min(start + chunk_size, text_len)  # é¿å…è¶Šç•Œ
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap

        if start < 0:
            start = 0
        if start >= text_len:
            break
    return chunks


def summarize_long_text(text):
    """
    å¯¹é•¿æ–‡æœ¬è¿›è¡Œå¤šæ®µå¼æ‘˜è¦ï¼Œç„¶ååˆå¹¶ã€‚
    """
    # åˆ†å—
    text_chunks = chunk_text(text, chunk_size=1500, overlap=200)
    chunk_summaries = []

    # é€å—æ‘˜è¦
    for idx, chunk in enumerate(text_chunks):
        prompt = f"è¯·é˜…è¯»ä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œå¹¶è¿›è¡Œç®€è¦æ€»ç»“ï¼š\n{chunk}\n\næ€»ç»“ï¼š"
        llm_response = get_llm_response_from_api(prompt)  # é€šè¿‡ API è·å–å“åº”
        chunk_summaries.append(llm_response.strip())

    # åˆå¹¶æ‰€æœ‰å—çš„æ‘˜è¦ï¼Œå†è®©æ¨¡å‹åšä¸€æ¬¡â€œæ€»æ€»ç»“â€
    combined_summary = "\n".join(chunk_summaries)
    final_prompt = f"ä»¥ä¸‹æ˜¯å¤šä¸ªåˆ†å—çš„æ€»ç»“ï¼Œè¯·å°†å…¶åˆå¹¶ä¸ºä¸€ä¸ªç®€æ´çš„æ•´ä½“æ€»ç»“ï¼š\n{combined_summary}\n\næ•´ä½“æ€»ç»“ï¼š"
    final_summary = get_llm_response_from_api(final_prompt)  # é€šè¿‡ API è·å–æ€»ç»“
    return final_summary.strip()


def rewrite_long_text(text):
    """
    å¯¹é•¿æ–‡æœ¬è¿›è¡Œâ€œæ”¹å†™ / æ¶¦è‰²â€ï¼Œä¸æ‘˜è¦ç±»ä¼¼çš„æ€è·¯ï¼Œå…ˆåˆ†å—å†åˆå¹¶ã€‚
    """
    # å…ˆç²—æš´ç¤ºä¾‹ï¼Œä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦æ‹†åˆ†åšå¤šæ¬¡æ”¹å†™
    text_chunks = chunk_text(text, chunk_size=1500, overlap=200)
    rewrite_results = []

    for chunk in text_chunks:
        prompt = f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²æˆ–æ”¹å†™ï¼Œä½¿å…¶æ›´é€šé¡ºã€ç®€æ´ï¼š\n{chunk}\n\næ”¹å†™åï¼š"
        rewrite_result = get_llm_response_from_api(prompt)  # é€šè¿‡ API è·å–æ”¹å†™
        rewrite_results.append(rewrite_result.strip())

    # ç®€å•æ‹¼æ¥ï¼Œå¦‚æœæƒ³å†åšæœ€ç»ˆåˆå¹¶ï¼Œå¯ä»¥å†æ¥ä¸€æ¬¡ç”Ÿæˆ
    return "\n".join(rewrite_results).strip()




##############################################################################
# 5. æœ€ç»ˆå›ç­”ï¼šgenerate_answer
#    - å¦‚æœç”¨æˆ·é—® "æ€»ç»“xxæ–‡ä»¶" æˆ– "æ”¹å†™xxæ–‡ä»¶"ï¼š
#         -> ç›´æ¥æ‰¾åˆ°æ–‡ä»¶å†…å®¹åš summarize/rewrite
#    - å¦åˆ™åšæ™®é€šRAGé—®ç­”
##############################################################################

def generate_answer(query):
    # 1) æ£€ç´¢æ–‡æ¡£
    related_docs = retrieve_top_k_documents(query, k=3)

    # 2) åŠ è½½ identity.mdï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    identity_content = ""
    if "identity.md" in filenames:
        identity_content = load_document_content("identity.md")

    # 3) æ‹¼æ¥ä¸Šä¸‹æ–‡
    context = f"AI Identity/Persona\n{identity_content}\n\nã€çŸ¥è¯†åº“æ£€ç´¢ç»“æœã€‘\n" + "\n\n".join(related_docs)

    # æ„é€  Prompt
    prompt = f"""
ä½ æ˜¯ä¸€åæ™ºèƒ½é—®ç­”åŠ©æ‰‹(æ‰®æ¼”DeepSeekçŸ¥è¯†ç®¡å®¶)ï¼Œä»¥ä¸‹æ˜¯ä½ çš„èº«ä»½æè¿°å’Œæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹:
{context}

è¯·éµå®ˆidentity.mdä¸­çš„æ‰€æœ‰â€œæ²Ÿé€šé£æ ¼å‡†åˆ™â€å’Œâ€œç‰¹æ®Šè¡Œä¸ºå‡†åˆ™â€ï¼Œå¹¶æ ¹æ®æ–‡æ¡£åšå‡ºå›ç­”ã€‚
å¦‚æœåœ¨çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¯·å›ç­”â€œå¯¹ä¸èµ·ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚
è¯·ä½¿ç”¨ç®€æ´ä¸”ä¸“ä¸šçš„å£å»ã€‚
ç”¨æˆ·çš„é—®é¢˜ï¼š{query}

è¯·ç›´æ¥ç»™å‡ºç®€æ´ä¸”ä¸“ä¸šçš„å›ç­”ï¼š
""".strip()

    # é€šè¿‡ API è·å–æµå¼å›ç­”
    llm_response = get_llm_response_from_api(prompt)
    return llm_response.strip()


##############################################################################
# 6. ç®€å•å‡½æ•°ï¼š_simple_summarize / _simple_rewrite (å¯¹çŸ­æ–‡æœ¬)
##############################################################################

def _simple_summarize(text):
    """
    å¯¹çŸ­æ–‡æœ¬åšä¸€æ¬¡æ€§æ‘˜è¦ã€‚å¦‚æœæ–‡æœ¬ä¸å¤§ï¼Œå¯ç›´æ¥ç”¨ã€‚
    """
    prompt = f"è¯·é˜…è¯»ä»¥ä¸‹æ–‡æœ¬å¹¶è¿›è¡Œç®€è¦æ€»ç»“ï¼š\n{text}\n\næ€»ç»“ï¼š"
    llm_response = get_llm_response_from_api(prompt)  # é€šè¿‡ API è·å–æ‘˜è¦
    return llm_response.strip()


def _simple_rewrite(text):
    """
    å¯¹çŸ­æ–‡æœ¬åšä¸€æ¬¡æ€§æ”¹å†™ã€‚
    """
    prompt = f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²æˆ–æ”¹å†™ï¼Œä½¿å…¶æ›´é€šé¡ºã€ç®€æ´ï¼š\n{text}\n\næ”¹å†™åï¼š"
    llm_response = get_llm_response_from_api(prompt)  # é€šè¿‡ API è·å–æ”¹å†™
    return llm_response.strip()


##############################################################################
# 7. å‘½ä»¤è¡Œäº¤äº’å…¥å£
##############################################################################


import re

if __name__ == "__main__":
    print("ğŸ“š RAG + Summarize/Rewrite ç¤ºä¾‹ç¨‹åºå¯åŠ¨...")
    try:
        while True:
            query = input("\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼‰ï¼š ")
            if query.lower().strip() == "exit":
                print("\nğŸ‘‹ é€€å‡º RAG ç³»ç»Ÿï¼Œå†è§ï¼")
                break

            # åˆå§‹åŒ–å˜é‡
            bot_response = ""
            debug_info = "æš‚æ— æ¨ç†è¿‡ç¨‹"
            current_output_buffer = ""

            # æµå¼å¤„ç†ç”Ÿæˆå™¨è¾“å‡º
            stream = generate_answer(query)
            for current_output in stream:
                current_output_buffer += current_output
                if "</think>" in current_output_buffer:
                    parts = current_output_buffer.split("</think>")
                    if len(parts) >= 2:
                        bot_response = parts[1].strip()  # æ¨¡å‹çš„å›ç­”
                        if len(parts) > 2:
                            debug_info = parts[2].strip()  # è°ƒè¯•ä¿¡æ¯
                        else:
                            debug_info = "æš‚æ— æ¨ç†è¿‡ç¨‹"
                        # æ¸…ç©ºç¼“å†²åŒº
                        current_output_buffer = ""
                        # æ‰“å°æµå¼è¾“å‡ºçš„å›ç­”
                        print("\nAI å›ç­”ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼š", bot_response, "\n")
                    else:
                        bot_response = parts[0].strip()
                        current_output_buffer = ""
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° </think>ï¼Œç»§ç»­ç§¯ç´¯è¾“å‡º
                    continue

            # å¦‚æœç¼“å†²åŒºä¸­è¿˜æœ‰å†…å®¹ï¼Œå¤„ç†å‰©ä½™éƒ¨åˆ†
            if current_output_buffer:
                bot_response = current_output_buffer.strip()
                print("\nAI å›ç­”ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼š", bot_response, "\n")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ£€æµ‹åˆ° Ctrl + Cï¼Œé€€å‡º RAG ç³»ç»Ÿï¼")

"""  æ¨¡å‹å›ç­” ä¸€æ¬¡æ€§è¾“å‡º
if __name__ == "__main__":
    print("ğŸ“š RAG + Summarize/Rewrite ç¤ºä¾‹ç¨‹åºå¯åŠ¨...")
    try:
        while True:
            query = input("\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼‰ï¼š ")
            if query.lower().strip() == "exit":
                print("\nğŸ‘‹ é€€å‡º RAG ç³»ç»Ÿï¼Œå†è§ï¼")
                break

            # åˆå§‹åŒ–å˜é‡
            bot_response = ""
            debug_info = "æš‚æ— æ¨ç†è¿‡ç¨‹"

            # æµå¼å¤„ç†ç”Ÿæˆå™¨è¾“å‡º
            stream = generate_answer(query)
            for current_output in stream:
                if "</think>" in current_output:
                    parts = current_output.split("</think>")
                    if len(parts) >= 2:
                        bot_response = parts[1].strip()  # æ¨¡å‹çš„å›ç­”
                        if len(parts) > 2:
                            debug_info = parts[2].strip()  # è°ƒè¯•ä¿¡æ¯
                    else:
                        bot_response = parts[0].strip()
                else:
                    bot_response = current_output.strip()

            # è¾“å‡ºæœ€ç»ˆå›ç­”
            print("\nAI å›ç­”ï¼š", bot_response, "\n")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ£€æµ‹åˆ° Ctrl + Cï¼Œé€€å‡º RAG ç³»ç»Ÿï¼")
"""

